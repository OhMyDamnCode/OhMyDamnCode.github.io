<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Python爬虫学习笔记 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="目录 (Table of Contents) [TOC] ###URLlib21urlopen(url, data, timeout)   第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。    第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT">
<meta name="keywords" content="技术,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫学习笔记">
<meta property="og:url" content="http://yoursite.com/2018/04/14/abc/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="目录 (Table of Contents) [TOC] ###URLlib21urlopen(url, data, timeout)   第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。    第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-04-14T15:16:12.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫学习笔记">
<meta name="twitter:description" content="目录 (Table of Contents) [TOC] ###URLlib21urlopen(url, data, timeout)   第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。    第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-abc" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/14/abc/" class="article-date">
  <time datetime="2018-04-14T15:09:10.000Z" itemprop="datePublished">2018-04-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/日志/">日志</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python爬虫学习笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>目录 (Table of Contents)</strong></p>
<p>[TOC]</p>
<p>###URLlib2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urlopen(url, data, timeout)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<ul>
<li>第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。</li>
</ul>
</blockquote>
<ul>
<li>第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT</li>
</ul>
<hr>
<p>###GET<br>　　是直接以链接形式访问，链接中包含了所有的参数，当然如果包含了密码的话是一种不安全的选择，不过你可以直观地看到自己提交了什么内容。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import urllib</span><br><span class="line">import urllib2</span><br><span class="line">values = &#123;&quot;username&quot;:&quot;username&quot;,&quot;password&quot;:&quot;password&quot;&#125;</span><br><span class="line">data = urllib.urlencode(values)</span><br><span class="line">url = &quot;https://mail.qq.com&quot;</span><br><span class="line">urlx = url+&quot;?&quot;+data</span><br><span class="line">request = urllib2.Request(urlx)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">print response.read()</span><br><span class="line">print urlx</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>引入urllib库，利用urllib的urlencode方法将字典编码</p>
</blockquote>
<hr>
<p>###POST<br>　　隐式传输参数，不会在网址上显示所有的参数，不过如果你想直接查看提交了什么就不太方便了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import urllib</span><br><span class="line">import urllib2</span><br><span class="line">values = &#123;&quot;username&quot;:&quot;username&quot;,&quot;password&quot;:&quot;password&quot;&#125;</span><br><span class="line">data = urllib.urlencode(values)</span><br><span class="line">url = &quot;http://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn&quot;</span><br><span class="line">request = urllib2.Request(url,data)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure></p>
<hr>
<p>###设置headers<br>　　有些网站不允许程序（爬虫）用上面的方式直接访问，站点根本不会响应。为了完全模拟浏览器的工作，需要设置 headers 的一些属性。</p>
<ul>
<li>使用 Chrome 浏览器随便打开一个网页，点击一项请求操作。</li>
<li>按F12进入开发者模式，选择 Network，选择 Name 列表中的第一项请求，可以看到 Request URL，Response Headers，Request Headers 等内容。</li>
<li>观察 Request Headers，可以看到这个头中包含了许多内容，有文件编码，压缩方式，User-Agent 等等。</li>
</ul>
<p>　　其中，User-Agent 就是请求的身份，如果没有写入请求身份，那么服务器不一定会响应，所以可以在 Request Headers 中设置 User-Agent。格式如下。</p>
<blockquote>
<p>User-Agent可以从Request Headers的User-Agent复制过来</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import urllib</span><br><span class="line">import urllib2</span><br><span class="line">url = &apos;http://https://www.baidu.com/&apos;</span><br><span class="line">user_agent = &apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64)&apos;</span><br><span class="line">values = &#123;&apos;username&apos;:&apos;username&apos;,&apos;password&apos;:&apos;password&apos;&#125;</span><br><span class="line">headers = &#123;&apos;User-Agent&apos;:user_agent&#125;</span><br><span class="line">data = urllib.urlencode(values)</span><br><span class="line">request = urllib2.Request(url, data, headers)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure>
<p>　　在对付防盗链时，服务器会识别 headers 中的 Referer 是不是它自己，如果不是，有的服务器不会响应，所以一般还应在 headers 中加入 referer：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64)&apos;,&apos;Referer&apos;:&apos;https://www.baidu.com/&apos;&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>####另外headers的一些属性<blockquote>
<ul>
<li>User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求</li>
<li>Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。</li>
<li>application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用</li>
<li>application/json ： 在 JSON RPC 调用时使用</li>
<li>application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用</li>
<li>在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务</li>
</ul>
</blockquote>
</li>
</ul>
<hr>
<p>###设置Proxy(代理)</p>
<p>　　urllib2 默认会使用环境变量 http_proxy 来设置 HTTP Proxy。如果一个网站通过检测IP访问次数，来限制访问，那么显然程序就会失效。所以可以通过设置一些代理服务器来帮助我们做工作，每隔一段时间换一个代理，让网站彻底眼瞎懵逼。</p>
<blockquote>
<p>代理的设置</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">enable_proxy = True</span><br><span class="line">proxy_handler = urllib2.ProxyHandler(&#123;&apos;https&apos;:&apos;https://mail.qq.com:8080&apos;&#125;)</span><br><span class="line">null_proxy_handler = urllib2.ProxyHandler(&#123;&#125;)</span><br><span class="line">if enable_proxy:</span><br><span class="line">	opener = urllib2.build_opnener(proxy_handler)</span><br><span class="line">else:</span><br><span class="line">	opener = urllib2.build_opnener(null_proxy_handler)</span><br><span class="line">urllib2.install_opener(opener)</span><br></pre></td></tr></table></figure>
<hr>
<p>###设置Timeout<br>　　urlopen 方法第三个参数就是 timeout，为解决一些网站响应过慢，可以设置等待多久超时。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response=urllib2.urlopen(url, data, timeout)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>如果第二个参数data为空，要特别指定是timeout是多少</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response=urllib2.urlopen(url, timeout=20)</span><br></pre></td></tr></table></figure>
<hr>
<p>###HTTP的 PUT 和 DELETE 方法<br>HTTP协议有6中请求方法：get，post，head，put，delete，options</p>
<blockquote>
<ul>
<li>PUT：较少见，HTML表单不支持。和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。</li>
<li>DELETE：删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。</li>
</ul>
</blockquote>
<p>　　使用 HTTP PUT 和 DELETE ，可以调用request的get_method方法，使 urllib2 发出 PUT 或 DELETE 请求。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import urllib2</span><br><span class="line">request = urllib2.Request(url, data)</span><br><span class="line">request.get_method = lambda: &apos;PUT&apos; # or &apos;DELETE&apos;</span><br><span class="line">response = urllib2.urlopen(request)</span><br></pre></td></tr></table></figure></p>
<hr>
<p>###DebugLog<br>可以通过 DebugLog 查看收发包的内容，方便调试。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import urllib2</span><br><span class="line">httpHandler = urllib2.HTTPHandler(debuglevel=1)</span><br><span class="line">httpsHandler = urllib2.HTTPSHandler(debuglevel=1)</span><br><span class="line">opener = urllib2.build_opener(httpHandler, httpsHandler)</span><br><span class="line">urllib2.install_opener(opener)</span><br><span class="line">response = urllib2.urlopen(&apos;http://www.baidu.com&apos;)</span><br></pre></td></tr></table></figure></p>
<hr>
<p>###URLError网络异常捕捉</p>
<ul>
<li><p>####URLError<br>产生网络异常的原因：</p>
<ul>
<li>网络无连接</li>
<li>找不到指定服务器</li>
<li>服务器不存在</li>
</ul>
<p>一般使用try-except语句进行捕捉：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import urllib2</span><br><span class="line">request = urllib2.Request(&apos;http://xxxxx.com&apos;)</span><br><span class="line">try:</span><br><span class="line">	response = urllib2.urlopen(request)</span><br><span class="line">except urllib2.URLError, e:</span><br><span class="line">	print e.reason</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>类似Java中的try-catch异常捕捉</p>
</blockquote>
<p> 程序运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Errno 11004] getaddrinfo failed</span><br></pre></td></tr></table></figure></p>
<p>错误代号11004，原因是 getaddrinfo failed</p>
<ul>
<li><p>####HTTPError<br>　　HTTPError 是 URLError 的子类，使用 urlopen 发出一个请求时，服务器上会应答一个 response 对象，其中包含一个“状态码”。对无法处理的对象，urlopen 会产生一个 HTTPError，对应相应的状态码。HTTP 状态码反映了响应的状态。</p>
<p><strong>下面将状态码归结如下：</strong></p>
<blockquote>
<ul>
<li>100：继续<br>客户端应当继续发送请求。如果请求已经完成，忽略这个响应。</li>
<li>101： 转换协议<br>在发送完这个响应最后的空行后，服务器将会切换到在 Upgrade 消息头中定义的那些协议。只有在切换新的协议更有好处的时候才应该采取类似措施。</li>
<li>102：继续处理<br>由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。</li>
<li>200：请求成功<br>处理方式：获得响应的内容，进行处理</li>
<li>201：请求完成，创建新资源。<br>新创建资源的URL可在响应的实体中得到处理方式：<strong>爬虫中不会遇到</strong></li>
<li>202：请求被接受，但处理尚未完成<br>处理方式：阻塞等待</li>
<li>204：服务器端已经实现了请求，但是没有返回新的信息。<br>如果客户是用户代理，则无须为此更新自身的文档视图。处理方式：丢弃</li>
<li>300：该状态码不被HTTP/1.0的应用程序直接使用， 只是作为3XX类型回应的默认解释。存在多个可用的被请求资源。<br>处理方式：若程序中能够处理，则进行进一步处理，如果程序中不能处理，则丢弃</li>
<li>301：请求到的资源都会分配一个永久的URL，这样就可以在将来通过该URL来访问此资源<br>处理方式：重定向到分配的URL</li>
<li>302：请求到的资源在一个不同的URL处临时保存<br>处理方式：重定向到临时的URL</li>
<li>304：请求的资源未更新<br>处理方式：丢弃</li>
<li>400：非法请求<br>处理方式：丢弃</li>
<li>401：未授权<br>处理方式：丢弃</li>
<li>403：禁止<br>处理方式：丢弃</li>
<li>404：没有找到<br>处理方式：丢弃</li>
<li>500：服务器内部错误<br>服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器端的源代码出现错误时出现。</li>
<li>501：服务器无法识别<br>服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。</li>
<li>502：错误网关<br>作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。</li>
<li>503：服务出错<br>由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。</li>
</ul>
</blockquote>
<p>HTTPError 实例化后会产生一个 code 属性，这就是服务器发送的状态码。<br>urllib2 能够自动处理重定向，也就是<strong>3</strong>开头的代号可以被处理；100-299 范围的号码表示成功，所以我们只能看到 400-599 的错误号码。</p>
<blockquote>
<p>下面写一个例子来感受一下，我们打印了reason属性，这是它的父类URLError的属性。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import urllib2</span><br><span class="line">request = urllib2.Request(&apos;http://www.baidu.com&apos;)</span><br><span class="line">try:</span><br><span class="line">	response = urllib2.urlopen(request)</span><br><span class="line">except urllib2.HTTPError, e:</span><br><span class="line">	print e.code</span><br><span class="line">	print e.reason</span><br></pre></td></tr></table></figure>
<blockquote>
<p>　　 我们知道，URLError是HTTPError的父类，根据编程经验，父类的异常应当写到子类异常的后面，如果子类捕获不到，还可以捕获父类的异常。上述代码except部分可以这么改写：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">except urllib2.HTTPError, e:</span><br><span class="line">	print e.code</span><br><span class="line">#如果捕获到了HTTPError，则输出code，不会再处理URLError异常</span><br><span class="line">except urllib2.URLError, e:</span><br><span class="line">	print e.reason</span><br><span class="line">else:</span><br><span class="line">	print &apos;OK&apos;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>或者可以使用 hasattr 属性提前对属性进行判断：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import urllib2</span><br><span class="line">request = urllib2.Request(&apos;http://www.baidu.com&apos;)</span><br><span class="line">try:</span><br><span class="line">	response = urllib2.urlopen(request)</span><br><span class="line">except urllib2.HTTPError, e:</span><br><span class="line">	if hasattr(e,&apos;reason&apos;):</span><br><span class="line">		print e.reason</span><br><span class="line">	else:</span><br><span class="line">	print &apos;OK&apos;</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/14/abc/" data-id="cjg2gwy1z0000dkw0fz09cbm5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/技术/">技术</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/04/14/abc/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          技术文档
        
      </div>
    </a>
  
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/日志/">日志</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开始/">开始</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/我/">我</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技术/">技术</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/日记/">日记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/开始/" style="font-size: 10px;">开始</a> <a href="/tags/我/" style="font-size: 10px;">我</a> <a href="/tags/技术/" style="font-size: 10px;">技术</a> <a href="/tags/日记/" style="font-size: 10px;">日记</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/14/abc/">技术文档</a>
          </li>
        
          <li>
            <a href="/2018/04/14/abc/">Python爬虫学习笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>